---
- name: "MLOps CI/CD Stages on Remote Host"
  hosts: server
  gather_facts: no 
  vars:
    # Variables passed from the Jenkinsfile environment
    dockerhub_user: "{{ lookup('env', 'DOCKER_CREDS_USR') }}"
    dockerhub_pass: "{{ lookup('env', 'DOCKER_CREDS_PSW') }}"
    k8s_namespace: "rottenpotatoes"
    kubeconfig_path: "{{ ansible_user_dir }}/.kube/config"
    backend_image: "{{ lookup('env', 'BACKEND_IMAGE') }}"
    frontend_image: "{{ lookup('env', 'FRONTEND_IMAGE') }}"
    docker_tag: "{{ lookup('env', 'DOCKER_TAG') }}"
  
  vars_files:
    - rotpot_vault.yml

  tasks:
    # Tasks related to directory management
    - name: Ensure project directory exists
      ansible.builtin.file:
        path: /home/{{ ansible_user }}/project_workspace
        state: directory
        owner: "{{ ansible_user }}"
        group: "{{ ansible_user }}" 
        mode: '0755'
      become: yes

    - name: Ensure MLflow history directory exists and is owned by user
      ansible.builtin.file:
        path: /home/{{ ansible_user }}/mlflow_history
        state: directory
        owner: "{{ ansible_user }}"
        group: "{{ ansible_user }}"
        mode: '0755'
      become: yes
      
    - name: Copy MLflow history to remote host
      ansible.builtin.synchronize:
        src: "/var/lib/jenkins/mlflow_history/"
        dest: "/home/{{ ansible_user }}/mlflow_history/"
        mode: push
        archive: yes
      become: yes

    - name: Copy Code, Config, and DVC Pointers
      ansible.builtin.synchronize:
        src: "{{ workspace }}/"
        dest: /home/{{ ansible_user }}/project_workspace/
        mode: push
        archive: yes
      args:
        rsync_opts:
          - "--exclude=.dvc/cache" 
      become: yes

    # Kubernetes pre-requisites
    - name: Get Minikube IP
      ansible.builtin.command: minikube ip
      register: minikube_ip_cmd
      become_user: "{{ ansible_user }}"
      become: yes

    - name: Add Minikube hostnames to /etc/hosts
      become: yes
      ansible.builtin.lineinfile:
        path: /etc/hosts
        line: "{{ minikube_ip_cmd.stdout }} rottenpotatoes.com kibana.com"
        state: present
      become: yes

    - name: Create rottenpotatoes namespace
      ansible.builtin.shell: |
        kubectl --kubeconfig={{ kubeconfig_path }} create namespace {{ k8s_namespace }} || true
      become: yes
        
    - name: Create Postgres Kubernetes Secret
      ansible.builtin.shell: |
        kubectl --kubeconfig={{ kubeconfig_path }} create secret generic postgres-secret \
          --from-literal=DB_HOST='{{ db_host }}' \
          --from-literal=POSTGRES_USER='{{ postgres_user }}' \
          --from-literal=POSTGRES_PASSWORD='{{ postgres_password }}' \
          --from-literal=POSTGRES_DB='{{ postgres_db }}' \
          --dry-run=client -o yaml | kubectl --kubeconfig={{ kubeconfig_path }} apply -f - -n {{ k8s_namespace }}
      args:
        chdir: "/home/{{ ansible_user }}/project_workspace/kubernetes"
      become: yes

    - name: Render backend.yaml with env variables on remote
      ansible.builtin.shell: |
        export BACKEND_IMAGE="{{ backend_image }}"
        export DOCKER_TAG="{{ docker_tag }}"
        envsubst < templates/backend.yaml.j2 > k8s-backend.yaml
      args:
        chdir: /home/{{ ansible_user }}/project_workspace/kubernetes
      become: yes


    - name: Render backend.yaml with env variables on remote
      ansible.builtin.shell: |
        export FRONTEND_IMAGE="{{ frontend_image }}"
        export DOCKER_TAG="{{ docker_tag }}"
        envsubst < templates/frontend.yaml.j2 > k8s-frontend.yaml
      args:
        chdir: /home/{{ ansible_user }}/project_workspace/kubernetes
      become: yes

    # Main sequence of tasks
    - name: 1. TRAIN MODEL & PREPARE FOR DEPLOYMENT
      ansible.builtin.shell: |
        echo "Starting MLOps training steps..."
        set -e
        cd /home/{{ ansible_user }}/project_workspace
        
        # Setup Venv
        rm -rf venv || true
        python3 -m venv venv
        . venv/bin/activate
        pip install --upgrade pip
        pip install -r requirements.txt

        # DVC: Uses the shared, permanent archive
        dvc remote remove mylocal || true
        dvc remote add -d -f mylocal /tmp/dvc_store
        dvc pull
        
        # Handle MLflow history link (Ensure path is consistent)
        ln -sf /home/{{ ansible_user }}/mlflow_history mlruns
        
        # Run Training Script (creates a new run/model in the linked mlruns)
        python3 train.py
        
        # --- MODEL DISCOVERY AND PREPARATION ---
        
        # 1. Clean up the 'mlruns' symbolic link safely (Fixes the 'Is a directory' error)
        # This prepares the directory for a clean copy of only the latest model
        unlink mlruns
        rm -rf mlruns/latest_model || true
        mkdir -p mlruns/latest_model

        # 2. Find the LATEST 'model.pkl' path based on modification time
        LATEST_LINE=$(find /home/{{ ansible_user }}/mlflow_history -name "model.pkl" -type f -printf "%T@ %p\n" | sort -n | tail -1)
        
        if [ -z "$LATEST_LINE" ]; then
            echo "ERROR: No new model.pkl found in MLflow history. Stopping deployment."
            exit 1
        fi
        
        # 3. Robustly extract the path by stripping the timestamp
        LATEST_PKL_PATH=$(echo "$LATEST_LINE" | sed 's/[^ ]* //')
        
        echo "Found latest model at: $LATEST_PKL_PATH"
        
        # 4. Get the ARTIFACT DIRECTORY (e.g., .../artifacts)
        ARTIFACT_DIR=$(dirname "$LATEST_PKL_PATH")
        
        # 5. Copy the entire artifact contents into the local 'latest_model' directory
        # This directory now contains model.pkl, MLmodel, conda.yaml, etc., ready for Docker.
        cp -rv "$ARTIFACT_DIR"/* mlruns/latest_model/

      args:
        chdir: /home/{{ ansible_user }}/project_workspace
      become_user: "{{ ansible_user }}"
      become: yes

    - name: 2. BUILD DOCKER IMAGES
      ansible.builtin.shell: |
        set -e
        cd /home/{{ ansible_user }}/project_workspace
        docker build -f Dockerfile.backend -t {{ backend_image }}:{{ docker_tag }} .
        docker build -f Dockerfile.frontend -t {{ frontend_image }}:{{ docker_tag }} .
      args:
        chdir: /home/{{ ansible_user }}/project_workspace/docker
      become: yes

    - name: 3. PUSH TO DOCKER HUB
      ansible.builtin.shell: |
        set -e
        cd /home/{{ ansible_user }}/project_workspace
        echo "{{ dockerhub_pass }}" | docker login -u "{{ dockerhub_user }}" --password-stdin
        docker push {{ backend_image }}:{{ docker_tag }}
        docker push {{ frontend_image }}:{{ docker_tag }}
        docker logout
      become: yes

    - name: 4. UPDATE KUBERNETES DEPLOYMENT
      ansible.builtin.shell: |
        set -e
        cd /home/{{ ansible_user }}/project_workspace/kubernetes

        kubectl --kubeconfig={{ kubeconfig_path }} apply -f k8s-logging.yaml -n {{ k8s_namespace }}
        kubectl --kubeconfig={{ kubeconfig_path }} apply -f k8s-database.yaml -n {{ k8s_namespace }}

        kubectl --kubeconfig={{ kubeconfig_path }} apply -f k8s-backend.yaml -n {{ k8s_namespace }}
        kubectl --kubeconfig={{ kubeconfig_path }} apply -f k8s-frontend.yaml -n {{ k8s_namespace }}

        kubectl --kubeconfig={{ kubeconfig_path }} apply -f k8s-ingress.yaml -n {{ k8s_namespace }}

        kubectl --kubeconfig={{ kubeconfig_path }} rollout restart deployment/backend-deployment -n {{ k8s_namespace }}
        kubectl --kubeconfig={{ kubeconfig_path }} rollout restart deployment/frontend-deployment -n {{ k8s_namespace }}
      become: yes

    - name: 5. DEPLOY LOGGING INFRASTRUCTURE
      ansible.builtin.shell: |
        kubectl --kubeconfig={{ kubeconfig_path }} rollout status deployment/kibana --timeout=300s -n {{ k8s_namespace }}
      args:
        chdir: /home/{{ ansible_user }}/project_workspace
      become: yes

    - name: 6. CONFIGURE KIBANA 
      ansible.builtin.uri:
        url: "http://kibana.com/api/saved_objects/index-pattern/rotten_potatoes_pattern"
        method: POST
        headers:
          kbn-xsrf: "true" # Required by Kibana to prove this isn't a hacker attack
          Content-Type: "application/json"
        body_format: json
        body:
          attributes:
            title: "rotten_potatoes_logs*"
            timeFieldName: "timestamp"
        status_code: [200, 409] 
      register: kibana_response
      retries: 10     
      delay: 10        
      until: kibana_response.status == 200 or kibana_response.status == 409
      become: yes

      